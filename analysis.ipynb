{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b486971d",
   "metadata": {},
   "source": [
    "# Traffic Volume Modeling Playbook\n",
    "\n",
    "**Goal:** walk through data ingestion, exploratory analysis, engineered-feature modeling, and AutoML benchmarking for the Kaggle traffic challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e48f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (5000, 10)\n",
      "Kaggle Shape: (6572, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2018-03-27 22:00:00</td>\n",
       "      <td>2058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>54.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Mist</td>\n",
       "      <td>mist</td>\n",
       "      <td>2017-04-25 09:00:00</td>\n",
       "      <td>5217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2018-02-04 14:00:00</td>\n",
       "      <td>3686</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mist</td>\n",
       "      <td>mist</td>\n",
       "      <td>2018-04-12 08:00:00</td>\n",
       "      <td>6198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2013-04-22 20:00:00</td>\n",
       "      <td>2063</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday  temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0     NaN  38.0      0.0      0.0           1        Clear   \n",
       "1     NaN  54.8      0.0      0.0          90         Mist   \n",
       "2     NaN   1.0      0.0      0.0           1        Clear   \n",
       "3     NaN  35.5      0.0      0.0           1         Mist   \n",
       "4     NaN  46.1      0.0      0.0          90         Rain   \n",
       "\n",
       "  weather_description           date_time  traffic_volume  ID  \n",
       "0        sky is clear 2018-03-27 22:00:00            2058   1  \n",
       "1                mist 2017-04-25 09:00:00            5217   2  \n",
       "2        sky is clear 2018-02-04 14:00:00            3686   3  \n",
       "3                mist 2018-04-12 08:00:00            6198   4  \n",
       "4          light rain 2013-04-22 20:00:00            2063   5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load Data\n",
    "train_df = pd.read_csv('TRAIN.csv', parse_dates=['date_time'])\n",
    "kaggle_df = pd.read_csv('KAGGLE.csv', parse_dates=['date_time'])\n",
    "\n",
    "print(\"Train Shape:\", train_df.shape)\n",
    "print(\"Kaggle Shape:\", kaggle_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda8d5e",
   "metadata": {},
   "source": [
    "# Final Blend Pipeline (Self-Contained)\n",
    "\n",
    "## Required Files\n",
    "**Input:**\n",
    "- `TRAIN.csv` - Raw training data with columns: `date_time`, `weather_description`, `temp`, `clouds_all`, `traffic_volume`\n",
    "- `KAGGLE.csv` - Raw test data with columns: `ID`, `date_time`, `weather_description`, `temp`, `clouds_all`\n",
    "- `prior_best_submission/*.csv` - (Optional) Your best prior submission for blending\n",
    "\n",
    "## Output Files\n",
    "- `artifacts_hgb_engineered_10fold/bagged_ensemble_engineered_10fold.csv` - Raw 10-fold predictions\n",
    "- `artifacts_hgb_engineered_10fold/bagged_ensemble_engineered_10fold_bias_corrected.csv` - Bias-corrected predictions\n",
    "- `artifacts_hgb_engineered_10fold/bagged_ensemble_engineered_10fold_metrics.json` - CV metrics\n",
    "- `blended_263_hgb10_bias_corrected.csv` - **Final blended submission**\n",
    "\n",
    "## Pipeline Steps\n",
    "1. Load raw data (`TRAIN.csv`, `KAGGLE.csv`)\n",
    "2. Engineer features (hour, dayofweek, year, dayofyear, weather_final, temp, clouds_all)\n",
    "3. Train 10-fold HGB ensemble\n",
    "4. Apply hour-of-week bias correction\n",
    "5. Blend with prior best submission (98% prior + 2% new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL BLEND PIPELINE (SELF-CONTAINED) ===\n",
    "# All-in-one cell: data loading, feature engineering, model training, blending, and submission\n",
    "from __future__ import annotations\n",
    "\n",
    "import inspect\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "# Input data files\n",
    "RAW_TRAIN_PATH = Path(\"TRAIN.csv\")\n",
    "RAW_KAGGLE_PATH = Path(\"KAGGLE.csv\")\n",
    "\n",
    "# Output paths\n",
    "ARTIFACTS = Path.cwd() / \"artifacts_hgb_engineered_10fold\"\n",
    "ARTIFACTS.mkdir(exist_ok=True)\n",
    "SUBMISSION_PATH = ARTIFACTS / \"bagged_ensemble_engineered_10fold.csv\"\n",
    "BIAS_CORRECTED_PATH = ARTIFACTS / \"bagged_ensemble_engineered_10fold_bias_corrected.csv\"\n",
    "METRICS_PATH = ARTIFACTS / \"bagged_ensemble_engineered_10fold_metrics.json\"\n",
    "\n",
    "# Prior best submission for blending (place your best CSV here)\n",
    "PRIOR_BEST_DIR = Path.cwd() / \"prior_best_submission\"\n",
    "PRIOR_BEST_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Model hyperparameters\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.03,\n",
    "    max_iter=3000,\n",
    "    max_depth=18,\n",
    "    max_leaf_nodes=84,\n",
    "    min_samples_leaf=15,\n",
    "    max_bins=160,\n",
    "    l2_regularization=0.10,\n",
    "    early_stopping=False,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "# Ensemble settings\n",
    "N_FOLDS = 10\n",
    "KF_RANDOM_STATE = 2025\n",
    "\n",
    "# Blend weight (alpha for prior best, 1-alpha for new model)\n",
    "BLEND_ALPHA = 0.98\n",
    "\n",
    "# Features used by the model\n",
    "STABLE_FEATURES = [\n",
    "    \"hour\",\n",
    "    \"dayofweek\",\n",
    "    \"year\",\n",
    "    \"dayofyear\",\n",
    "    \"weather_final\",\n",
    "    \"temp\",\n",
    "    \"clouds_all\",\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE ENGINEERING (SELF-CONTAINED)\n",
    "# =============================================================================\n",
    "def create_weather_final(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Create validated 8-level weather feature from raw weather_description.\"\"\"\n",
    "    desc = df[\"weather_description\"].str.lower().str.strip()\n",
    "    \n",
    "    conditions = [\n",
    "        desc.isin([\"sky is clear\", \"overcast clouds\"]),\n",
    "        desc.isin([\"few clouds\", \"broken clouds\", \"scattered clouds\", \"haze\"]),\n",
    "        desc.isin([\"mist\", \"fog\"]),\n",
    "        desc.isin([\n",
    "            \"light rain\", \"drizzle\", \"light intensity drizzle\",\n",
    "            \"light rain and snow\", \"light intensity shower rain\",\n",
    "        ]),\n",
    "        desc.isin([\n",
    "            \"moderate rain\", \"heavy intensity rain\", \"freezing rain\",\n",
    "            \"heavy intensity drizzle\", \"shower drizzle\", \"proximity shower rain\",\n",
    "        ]),\n",
    "        desc.isin([\"light snow\", \"light shower snow\"]),\n",
    "        desc.isin([\"snow\", \"heavy snow\", \"sleet\", \"shower snow\"]),\n",
    "        desc.str.contains(\"thunderstorm\", na=False),\n",
    "    ]\n",
    "    \n",
    "    choices = [\n",
    "        \"Best_Conditions\",\n",
    "        \"Cloudy_Hazy\",\n",
    "        \"Low_Viz\",\n",
    "        \"Rain_Light\",\n",
    "        \"Rain_ModHeavy\",\n",
    "        \"Snow_Light\",\n",
    "        \"Snow_ModHeavy\",\n",
    "        \"Thunderstorm\",\n",
    "    ]\n",
    "    \n",
    "    return np.select(conditions, choices, default=\"Other\")\n",
    "\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Engineer all required features for the HGB model.\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Parse datetime\n",
    "    dt = pd.to_datetime(data[\"date_time\"], utc=False, errors=\"coerce\")\n",
    "    \n",
    "    # Time features\n",
    "    data[\"hour\"] = dt.dt.hour\n",
    "    data[\"dayofweek\"] = dt.dt.dayofweek\n",
    "    data[\"year\"] = dt.dt.year\n",
    "    data[\"dayofyear\"] = dt.dt.dayofyear\n",
    "    \n",
    "    # Weather feature\n",
    "    data[\"weather_final\"] = create_weather_final(data)\n",
    "    \n",
    "    # Keep original temp and clouds_all (should already exist)\n",
    "    # If temp is in Kelvin, convert to Fahrenheit\n",
    "    if \"temp\" in data.columns:\n",
    "        if data[\"temp\"].mean() > 200:  # likely Kelvin\n",
    "            data[\"temp\"] = (data[\"temp\"] - 273.15) * 9/5 + 32\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def _ensure_datetime(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Ensure series is datetime type.\"\"\"\n",
    "    if series.dtype.kind == \"M\":\n",
    "        return series\n",
    "    return pd.to_datetime(series, utc=False, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def build_engineered_frame(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Run engineer_features and attach auxiliary fields needed downstream.\"\"\"\n",
    "    engineered = engineer_features(df_in)\n",
    "    frame = engineered.copy()\n",
    "    \n",
    "    frame[\"dayofweek\"] = frame[\"dayofweek\"].astype(\"category\")\n",
    "    frame[\"weather_final\"] = frame[\"weather_final\"].astype(\"category\")\n",
    "    \n",
    "    if \"traffic_volume\" in df_in.columns:\n",
    "        traffic = df_in[\"traffic_volume\"].astype(float)\n",
    "        frame[\"traffic_volume\"] = traffic.values\n",
    "        frame[\"traffic_volume_log\"] = np.log1p(traffic).values\n",
    "    \n",
    "    if \"ID\" in df_in.columns:\n",
    "        frame[\"ID\"] = df_in[\"ID\"].values\n",
    "    \n",
    "    if \"date_time\" in df_in.columns:\n",
    "        dt = _ensure_datetime(df_in[\"date_time\"])\n",
    "        frame[\"date_time\"] = dt\n",
    "        frame[\"time_index\"] = (dt - dt.min()).dt.total_seconds() / 3600.0\n",
    "    else:\n",
    "        frame[\"time_index\"] = np.arange(len(frame), dtype=float)\n",
    "    \n",
    "    frame[\"dayofweek_numeric\"] = frame[\"dayofweek\"].astype(str).astype(int)\n",
    "    frame[\"day_of_week\"] = frame[\"dayofweek_numeric\"]\n",
    "    frame[\"hour_of_week\"] = frame[\"dayofweek_numeric\"] * 24 + frame[\"hour\"]\n",
    "    \n",
    "    return frame.sort_values(\"time_index\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def build_X_y(train_eng: pd.DataFrame):\n",
    "    \"\"\"Split engineered train frame into X, y using the locked feature set.\"\"\"\n",
    "    if \"traffic_volume\" not in train_eng.columns:\n",
    "        raise ValueError(\"Expected column 'traffic_volume' in engineered train frame.\")\n",
    "    \n",
    "    X = train_eng[STABLE_FEATURES].copy()\n",
    "    y = train_eng[\"traffic_volume\"].astype(float)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def build_kaggle_X(kaggle_eng: pd.DataFrame, train_X_columns: list[str]):\n",
    "    \"\"\"Build Kaggle feature frame matching the columns used in training.\"\"\"\n",
    "    Xk = kaggle_eng[STABLE_FEATURES].copy()\n",
    "    \n",
    "    for col in train_X_columns:\n",
    "        if col not in Xk.columns:\n",
    "            Xk[col] = 0.0\n",
    "    \n",
    "    return Xk[train_X_columns]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PIPELINE BUILDER\n",
    "# =============================================================================\n",
    "def build_pipeline(features: pd.DataFrame) -> Pipeline:\n",
    "    \"\"\"Create preprocessing + HGB model pipeline.\"\"\"\n",
    "    categorical_cols = features.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    numeric_cols = [col for col in features.columns if col not in categorical_cols]\n",
    "    \n",
    "    onehot_kwargs = {\"handle_unknown\": \"ignore\"}\n",
    "    if \"sparse_output\" in inspect.signature(OneHotEncoder.__init__).parameters:\n",
    "        onehot_kwargs[\"sparse_output\"] = False\n",
    "    else:\n",
    "        onehot_kwargs[\"sparse\"] = False\n",
    "    \n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", OneHotEncoder(**onehot_kwargs), categorical_cols),\n",
    "            (\"numeric\", \"passthrough\", numeric_cols),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model = HistGradientBoostingRegressor(**BASE_PARAMS)\n",
    "    \n",
    "    return Pipeline([\n",
    "        (\"preprocessor\", transformer),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BIAS CORRECTION\n",
    "# =============================================================================\n",
    "def apply_bias_correction(\n",
    "    train_eng: pd.DataFrame,\n",
    "    kaggle_eng: pd.DataFrame,\n",
    "    oof_preds: np.ndarray,\n",
    "    kaggle_preds: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Apply hour-of-week bias correction to Kaggle predictions.\"\"\"\n",
    "    y_true = train_eng[\"traffic_volume\"].values\n",
    "    residuals = y_true - oof_preds\n",
    "    \n",
    "    # Compute mean residual per hour_of_week\n",
    "    train_eng = train_eng.copy()\n",
    "    train_eng[\"residual\"] = residuals\n",
    "    hw_bias = train_eng.groupby(\"hour_of_week\")[\"residual\"].mean()\n",
    "    \n",
    "    # Apply correction to Kaggle predictions\n",
    "    kaggle_hw = kaggle_eng[\"hour_of_week\"].values\n",
    "    corrections = pd.Series(kaggle_hw).map(hw_bias).fillna(0.0).values\n",
    "    \n",
    "    corrected = kaggle_preds + corrections\n",
    "    return np.clip(corrected, 0, None)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN PIPELINE\n",
    "# =============================================================================\n",
    "def run_final_blend_pipeline():\n",
    "    \"\"\"Execute the complete pipeline: train, predict, correct bias, and blend.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"FINAL BLEND PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # --- Load Data ---\n",
    "    print(\"\\n[1/6] Loading data...\")\n",
    "    train_df = pd.read_csv(RAW_TRAIN_PATH, parse_dates=[\"date_time\"])\n",
    "    kaggle_df = pd.read_csv(RAW_KAGGLE_PATH, parse_dates=[\"date_time\"])\n",
    "    print(f\"  Train: {train_df.shape[0]:,} rows\")\n",
    "    print(f\"  Kaggle: {kaggle_df.shape[0]:,} rows\")\n",
    "    \n",
    "    # --- Engineer Features ---\n",
    "    print(\"\\n[2/6] Engineering features...\")\n",
    "    train_eng = build_engineered_frame(train_df)\n",
    "    kaggle_eng = build_engineered_frame(kaggle_df)\n",
    "    \n",
    "    X, y = build_X_y(train_eng)\n",
    "    train_X_cols = X.columns.tolist()\n",
    "    X_kaggle = build_kaggle_X(kaggle_eng, train_X_cols)\n",
    "    \n",
    "    print(f\"  Training features: {X.shape}\")\n",
    "    print(f\"  Kaggle features: {X_kaggle.shape}\")\n",
    "    print(f\"  Features: {train_X_cols}\")\n",
    "    \n",
    "    # --- Train 10-Fold Ensemble ---\n",
    "    print(f\"\\n[3/6] Training {N_FOLDS}-fold HGB ensemble...\")\n",
    "    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=KF_RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros(len(X), dtype=float)\n",
    "    prediction_counts = np.zeros(len(X), dtype=float)\n",
    "    kaggle_predictions = np.zeros(X_kaggle.shape[0], dtype=float)\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y), start=1):\n",
    "        print(f\"  Fold {fold}/{N_FOLDS}...\", end=\" \")\n",
    "        \n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        X_val_fold = X.iloc[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "        \n",
    "        pipeline = build_pipeline(X_train_fold)\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        val_preds = pipeline.predict(X_val_fold)\n",
    "        oof_predictions[val_idx] += val_preds\n",
    "        prediction_counts[val_idx] += 1\n",
    "        \n",
    "        fold_rmse = mean_squared_error(y_val_fold, val_preds, squared=False)\n",
    "        fold_metrics.append({\"fold\": fold, \"rmse\": float(fold_rmse)})\n",
    "        print(f\"RMSE: {fold_rmse:.3f}\")\n",
    "        \n",
    "        kaggle_predictions += pipeline.predict(X_kaggle) / N_FOLDS\n",
    "    \n",
    "    prediction_counts[prediction_counts == 0] = 1.0\n",
    "    oof_predictions /= prediction_counts\n",
    "    \n",
    "    overall_oof_rmse = float(mean_squared_error(y, oof_predictions, squared=False))\n",
    "    print(f\"\\n  Overall OOF RMSE: {overall_oof_rmse:.3f}\")\n",
    "    \n",
    "    # Save artifacts\n",
    "    np.save(ARTIFACTS / \"oof_preds.npy\", oof_predictions)\n",
    "    np.save(ARTIFACTS / \"y_true.npy\", y.to_numpy())\n",
    "    \n",
    "    metrics = {\n",
    "        \"overall_oof_rmse\": overall_oof_rmse,\n",
    "        \"base_model_params\": BASE_PARAMS,\n",
    "        \"n_folds\": N_FOLDS,\n",
    "        \"fold_metrics\": fold_metrics,\n",
    "        \"feature_columns\": train_X_cols,\n",
    "    }\n",
    "    METRICS_PATH.write_text(json.dumps(metrics, indent=2))\n",
    "    \n",
    "    # Save raw submission\n",
    "    raw_submission = pd.DataFrame({\n",
    "        \"ID\": kaggle_eng.get(\"ID\", pd.Series(np.arange(len(X_kaggle)))).values,\n",
    "        \"traffic_volume\": kaggle_predictions,\n",
    "    })\n",
    "    raw_submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "    print(f\"\\n[4/6] Raw submission saved: {SUBMISSION_PATH.name}\")\n",
    "    \n",
    "    # --- Apply Bias Correction ---\n",
    "    print(\"\\n[5/6] Applying bias correction...\")\n",
    "    kaggle_predictions_corrected = apply_bias_correction(\n",
    "        train_eng, kaggle_eng, oof_predictions, kaggle_predictions\n",
    "    )\n",
    "    \n",
    "    corrected_submission = pd.DataFrame({\n",
    "        \"ID\": kaggle_eng.get(\"ID\", pd.Series(np.arange(len(X_kaggle)))).values,\n",
    "        \"traffic_volume\": kaggle_predictions_corrected,\n",
    "    })\n",
    "    corrected_submission.to_csv(BIAS_CORRECTED_PATH, index=False)\n",
    "    print(f\"  Bias-corrected submission saved: {BIAS_CORRECTED_PATH.name}\")\n",
    "    \n",
    "    # --- Blend with Prior Best ---\n",
    "    print(\"\\n[6/6] Blending with prior best submission...\")\n",
    "    \n",
    "    # Find prior best CSV\n",
    "    prior_best_path = None\n",
    "    if PRIOR_BEST_DIR.exists():\n",
    "        csv_files = list(PRIOR_BEST_DIR.glob(\"*.csv\"))\n",
    "        if csv_files:\n",
    "            prior_best_path = max(csv_files, key=lambda p: p.stat().st_mtime)\n",
    "    \n",
    "    if prior_best_path is None:\n",
    "        print(f\"  WARNING: No prior best CSV found in {PRIOR_BEST_DIR}\")\n",
    "        print(f\"  Place your best submission CSV in that folder to enable blending.\")\n",
    "        print(f\"  Using bias-corrected submission as final output.\")\n",
    "        final_submission = corrected_submission.copy()\n",
    "        final_path = BIAS_CORRECTED_PATH.with_name(\"final_submission.csv\")\n",
    "    else:\n",
    "        print(f\"  Prior best: {prior_best_path.name}\")\n",
    "        prior_best = pd.read_csv(prior_best_path)\n",
    "        \n",
    "        merged = prior_best.merge(\n",
    "            corrected_submission,\n",
    "            on=\"ID\",\n",
    "            suffixes=(\"_prior\", \"_new\")\n",
    "        )\n",
    "        \n",
    "        y_prior = merged[\"traffic_volume_prior\"].to_numpy()\n",
    "        y_new = merged[\"traffic_volume_new\"].to_numpy()\n",
    "        y_blend = BLEND_ALPHA * y_prior + (1 - BLEND_ALPHA) * y_new\n",
    "        \n",
    "        final_submission = pd.DataFrame({\n",
    "            \"ID\": merged[\"ID\"],\n",
    "            \"traffic_volume\": y_blend,\n",
    "        })\n",
    "        \n",
    "        final_path = Path.cwd() / \"blended_263_hgb10_bias_corrected.csv\"\n",
    "        print(f\"  Blend: {BLEND_ALPHA:.0%} prior + {1-BLEND_ALPHA:.0%} new\")\n",
    "    \n",
    "    final_submission.to_csv(final_path, index=False)\n",
    "    print(f\"  Final submission saved: {final_path.name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PIPELINE COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        \"train_eng\": train_eng,\n",
    "        \"kaggle_eng\": kaggle_eng,\n",
    "        \"oof_preds\": oof_predictions,\n",
    "        \"kaggle_preds\": kaggle_predictions,\n",
    "        \"kaggle_preds_corrected\": kaggle_predictions_corrected,\n",
    "        \"final_submission\": final_submission,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "\n",
    "\n",
    "# Run the pipeline\n",
    "results = run_final_blend_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67b8bd",
   "metadata": {},
   "source": [
    "# Plots for HW_9.docx Report\n",
    "\n",
    "This cell generates all visualizations required for the deliverables:\n",
    "1. **Hour Ã— Day-of-Week Interaction Heatmap** - Shows traffic patterns across the week\n",
    "2. **Weather vs Traffic Volume Boxplot** - Impact of weather_final categories\n",
    "3. **Temperature vs Traffic Volume** - Relationship with temperature\n",
    "4. **Holiday Impact Visualization** - Traffic reduction on holidays\n",
    "5. **Model Pipeline Diagram** - How predictions are assembled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
